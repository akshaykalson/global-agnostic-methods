# -*- coding: utf-8 -*-
"""Explainable ML_exercise 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oe5bJE-1KAIRZ_ioMygwtm7YWCFVSzOE

Checking NaN Values:
You can check for NaN values in a DataFrame using pandas:

# Check for NaN values in a DataFrame
nan_values = your_dataframe.isnull().sum()
Handling Nominal Values:
Nominal values, typically categorical variables, can be handled in various ways:

One-Hot Encoding: Convert categorical variables into binary vectors.
Label Encoding: Encode categorical variables numerically.
Ordinal Encoding: Assign integers to categories based on their order.
For instance, using pandas:

# One-Hot Encoding with pandas
encoded_df = pd.get_dummies(your_dataframe, columns=['nominal_column'])
Scaling Values:
Scaling values is crucial to ensure features are on a similar scale, preventing certain features from dominating due to their magnitude. Popular scaling methods include:

Standardization: Scale features to have mean of 0 and variance of 1.
Normalization (Min-Max Scaling): Scale features to a range (usually 0 to 1).
With sklearn:

from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Standardization
scaler = StandardScaler()
scaled_data = scaler.fit_transform(your_data)

# Min-Max Scaling
minmax_scaler = MinMaxScaler()
scaled_data = minmax_scaler.fit_transform(your_data)

Shapley Values:
Shapley values come from cooperative game theory. In the context of machine learning, Shapley values represent the average marginal contribution of a feature value across all possible coalitions of features. They provide a way to understand the impact of each feature on a model's output prediction for a specific instance. Tools like SHAP (SHapley Additive exPlanations) utilize Shapley values to explain individual predictions in machine learning models, aiding interpretability.

For example, using the shap library in Python:

import shap

# Create an explainer object for a specific model
explainer = shap.Explainer(your_model, your_data)
shap_values = explainer(your_data)

These shap_values can then be used to interpret individual predictions and understand feature importance in your machine learning model.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np

# Read the Excel file
data = pd.read_excel('/content/fueleconomy.xlsx')

# Selecting specific columns
X = data[['co2TailpipeGpm', 'Year', 'displ', 'co2', 'pv4', 'cylinders', 'lv4', 'hlv', 'ghgScore']]
y = data['comb08']  # 'comb08' is set as the target variable

# Splitting the data into training, validation, and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=9)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=9)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization

# Assuming X_train, X_val, X_test, y_train, y_val, y_test are already defined

# Normalizing the data
normalizer = tf.keras.layers.Normalization()
normalizer.adapt(X_train.to_numpy())

# Sequential model
model = Sequential()

# Adding normalization layer
model.add(normalizer)

# Adding hidden layers
model.add(Dense(64, activation='relu'))  # First hidden layer with 64 nodes
model.add(Dense(64, activation='relu'))  # Second hidden layer with 64 nodes

# Output layer
model.add(Dense(1))  # Output layer with 1 node (for regression tasks)

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Using Mean Squared Error as loss

# Training the model
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Assuming you have your data loaded and prepared as X_train, y_train

# Creating a Sequential model
# Define the Sequential model
fitted_nn_model = tf.keras.Sequential([
    tf.keras.Input(shape=(X_train.shape[1],)),  # Input layer
    tf.keras.layers.experimental.preprocessing.Normalization(),  # Normalization layer
    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 1 with 64 nodes and ReLU activation
    tf.keras.layers.Dense(64, activation='relu'),  # Hidden layer 2 with 64 nodes and ReLU activation
    tf.keras.layers.Dense(1)  # Output layer
])


# Compile the model
fitted_nn_model.compile(loss='mean_squared_error',
                        optimizer=tf.keras.optimizers.Adam(lr=0.0005),
                        metrics=['mse'])

# Printing model summary
print('fitted_nn_model.summary()\n', fitted_nn_model.summary())

# Define the EarlyStopping callback
es = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    mode='min',
    verbose=1,
    patience=50,
    min_delta=0.0005,
    restore_best_weights=True
)

# Training the model with early stopping
nn_history = fitted_nn_model.fit(
    X_train.astype(float), y_train.astype(float),
    epochs=100,
    batch_size=128,
    validation_data=(X_val.values.astype(float), y_val.values.astype(float)),
    verbose=1,
    callbacks=[es]
)

!pip install plot_keras_history

import matplotlib.pyplot as plt
from plot_keras_history import plot_history, show_history

# Assuming 'nn_history' contains the training history from the model.fit() function

# Print loss and mean squared error from history
print("Training Loss:", nn_history.history['loss'])
print("Training MSE:", nn_history.history['mse'])
print("Validation Loss:", nn_history.history['val_loss'])
print("Validation MSE:", nn_history.history['val_mse'])

# Show and plot the training history
show_history(nn_history)
plot_history(nn_history, path="standard.png")
plt.close()

from sklearn import metrics

# Assuming fitted_nn_model is your trained neural network model

# Predictions on the training and test sets
y_train_nn_pred = fitted_nn_model.predict(X_train.astype(float)).flatten()
y_test_nn_pred = fitted_nn_model.predict(X_test.astype(float)).flatten()

# Calculate RMSE for training and test sets
RMSE_nn_train = metrics.mean_squared_error(y_train, y_train_nn_pred, squared=False)
RMSE_nn_test = metrics.mean_squared_error(y_test, y_test_nn_pred, squared=False)

# Calculate R-squared for the test set
R2_nn_test = metrics.r2_score(y_test, y_test_nn_pred)

# Print the evaluation metrics
print('RMSE_train: %.4f\tRMSE_test: %.4f\tR2: %.4f' % (RMSE_nn_train, RMSE_nn_test, R2_nn_test))

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming y_test and y_test_nn_pred contain your actual and predicted values for 'comb08'

plt.figure(figsize=(12, 12))
plt.title('Keras NN: Observed vs Predicted Y', fontsize=16)
plt.ylabel('Predicted Combined MPG', fontsize=14)
plt.xlabel('Observed Combined MPG (comb08)', fontsize=14)

# Creating a scatter plot
sns.regplot(x=y_test, y=y_test_nn_pred, color="g", scatter_kws={'alpha': 0.3})

plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming y_test and y_test_nn_pred contain your actual and predicted values for 'comb08'

plt.figure(figsize=(12, 12))
plt.title('Keras NN: Observed vs Predicted Y', fontsize=16)
plt.ylabel('Predicted Combined MPG', fontsize=14)
plt.xlabel('Observed Combined MPG (comb08)', fontsize=14)

# Creating a scatter plot
sns.regplot(x=y_test, y=y_test_nn_pred, color="g", scatter_kws={'alpha': 0.3})

plt.show()

import xgboost as xgb

dtrain = xgb.DMatrix(X_train, label=y_train)
dval = xgb.DMatrix (X_val, label=y_val)
dtest = xgb.DMatrix(X_test, label=y_test)

import xgboost as xgb
from sklearn.metrics import mean_squared_error

# Creating and training the XGBoost model
fitted_xgb_model = xgb.XGBRegressor(
    max_depth=7,
    learning_rate=0.6,
    n_estimators=50,
    n_jobs=4,
    objective='reg:squarederror',
    random_state=9  # Assuming 'rand' is defined earlier
)

# Fitting the model to the training data and evaluating on validation data
fitted_xgb_model.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_val, y_val)],
    eval_metric='rmse',
    verbose=True  # Set to True to see evaluation results
)

# Predictions on the validation set
y_val_pred = fitted_xgb_model.predict(X_val)

# Calculating RMSE on the validation set
rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)
print(f"Validation Set RMSE: {rmse_val}")

# Retrieve evaluation results from the XGBoost model
evals_result = fitted_xgb_model.evals_result()

# Extract RMSE values for training and validation sets
train_rmse = evals_result['validation_0']['rmse']
val_rmse = evals_result['validation_1']['rmse']

# Plotting the RMSE values during training
plt.figure(figsize=(14, 10))
plt.rcParams.update({'font.size': 14})

plt.plot(train_rmse, label='Train')
plt.plot(val_rmse, label='Val')

plt.ylabel('RMSE [Combined MPG]', fontsize=14)
plt.ylim([0, 8])
plt.xlabel('Round', fontsize=14)

plt.legend(loc='upper right')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Set the seaborn style
sns.set()

# Plotting feature importance
fig, ax = plt.subplots(figsize=(12, 8))
xgb.plot_importance(
    fitted_xgb_model,
    max_num_features=12,
    ax=ax,
    importance_type="weight"  # 'weight' represents the number of times a feature appears in a tree
)
plt.show()

!pip install shap
import shap

# Create a SHAP explainer for the XGBoost model
shap_xgb_explainer = shap.TreeExplainer(fitted_xgb_model)

# Get SHAP values for the training data
shap_xgb_values_train = shap_xgb_explainer.shap_values(X_train)
print(shap_xgb_values_train.shape)  # Shape of SHAP values for the training data

# Get SHAP values for the test data
shap_xgb_values_test = shap_xgb_explainer.shap_values(X_test)
print(shap_xgb_values_test.shape)  # Shape of SHAP values for the test data

# Summary plot for training data
shap.summary_plot(shap_xgb_values_train, X_train, plot_type="dot")

# Summary plot for test data
shap.summary_plot(shap_xgb_values_test, X_test, plot_type="dot")

# Assuming X_train is your original training data
background = X_train.iloc[np.random.choice(X_train.shape[0], 150, replace=False)]

print(background.shape)  # Print the shape of the background dataset

# Creating the SHAP GradientExplainer for the neural network model
shap_nn_explainer = shap.GradientExplainer(fitted_nn_model, background.astype(float).values)

# Compute SHAP values for the test data
shap_nn_values_test = shap_nn_explainer.shap_values(X_test.astype(float).values)

# Check the type of SHAP values and the shape of the first element
print(type(shap_nn_values_test))  # Print the type of SHAP values
print(shap_nn_values_test[0].shape)  # Print the shape of the first element

# Generate SHAP summary plot
shap.summary_plot(shap_nn_values_test[0], X_test, plot_type="dot")

# Generate SHAP summary plot with bars
shap.summary_plot(shap_nn_values_test[0], X_test, plot_type="bar")

# Define the list of top features
top_features_l = ['comb08', 'co2TailpipeGpm', 'Year', 'displ', 'co2', 'pv4', 'cylinders', 'lv4', 'hlv', 'ghgScore']

# Create DataFrame containing specific columns for rows indexed by X_train
top_df = data.loc[X_train.index, top_features_l]

from scipy import stats

corrs = stats.spearmanr(top_df).correlation

mask = np.zeros_like(corrs)
mask[np.triu_indices_from(mask)] = True
ax = sns.heatmap(
corrs,
vmin=-1, vmax=1, center=0,
cmap=sns.diverging_palette(20, 220, n=200),
xticklabels=top_df.columns,
yticklabels=top_df.columns,
mask=mask,
square=True
)
ax.set_xticklabels(
ax.get_xticklabels(),
rotation=45,
horizontalalignment='right'
)
plt.show()

# correlation hypothesis test
print('spearman\tco2TailpipeGpm→comb08\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(X_train.co2TailpipeGpm.values, top_df.comb08.values)))
print('spearman\tco2→comb08\t\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(X_train.co2.values, top_df.comb08.values)))
print('spearman\tyear→comb08\t\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(X_train.Year.values, top_df.comb08.values)))
print('spearman\tghgScore→comb08\t\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(top_df.ghgScore.values, top_df.comb08.values)))
print('spearman\tcylinders→comb08\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(X_train.cylinders.values, top_df.comb08.values)))
print('spearman\tghgScore→cylinders\t\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(top_df.ghgScore.values, top_df.cylinders.values)))
print('spearman\tcylinders→co2TailpipeGpm\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(X_train.cylinders.values, X_train.co2TailpipeGpm.values)))

print('spearman\tco2TailpipeGpm→Year\t\tcorr: %.3f\tp-val: %.4f' %
(stats.spearmanr(top_df.co2TailpipeGpm.values, top_df.Year.values)))
shap.dependence_plot("co2TailpipeGpm", shap_xgb_values_test, X_test,\
interaction_index="Year", show=False, alpha=0.3)
fig = plt.gcf()
fig.set_size_inches(12,8)
plt.show()

import shap
import xgboost as xgb
import matplotlib.pyplot as plt

# Assuming you've defined fitted_xgb_model and X_test previously
# Create a SHAP explainer for the XGBoost model
explainer = shap.Explainer(fitted_xgb_model, X_test)

# Calculate SHAP values
shap_values = explainer(X_test)

# Plot summary plot for feature importance using SHAP
shap.summary_plot(shap_values, X_test)
plt.show()